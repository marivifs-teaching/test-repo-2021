{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\admin\\anaconda3\\lib\\site-packages (2.4.1)\n",
      "Requirement already satisfied: h5py~=2.10.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from tensorflow) (2.10.0)\n",
      "Requirement already satisfied: wheel~=0.35 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from tensorflow) (0.36.2)\n",
      "Requirement already satisfied: tensorflow-estimator<2.5.0,>=2.4.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from tensorflow) (2.4.0)\n",
      "Requirement already satisfied: six~=1.15.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from tensorflow) (1.15.0)\n",
      "Requirement already satisfied: google-pasta~=0.2 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: astunparse~=1.6.3 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: numpy~=1.19.2 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from tensorflow) (1.19.5)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from tensorflow) (3.16.0)\n",
      "Requirement already satisfied: opt-einsum~=3.3.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: flatbuffers~=1.12.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from tensorflow) (1.12)\n",
      "Requirement already satisfied: keras-preprocessing~=1.1.2 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: typing-extensions~=3.7.4 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from tensorflow) (3.7.4.2)\n",
      "Requirement already satisfied: wrapt~=1.12.1 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from tensorflow) (1.12.1)\n",
      "Requirement already satisfied: gast==0.3.3 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from tensorflow) (0.3.3)\n",
      "Requirement already satisfied: grpcio~=1.32.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from tensorflow) (1.32.0)\n",
      "Requirement already satisfied: termcolor~=1.1.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: tensorboard~=2.4 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from tensorflow) (2.5.0)\n",
      "Requirement already satisfied: absl-py~=0.10 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from tensorflow) (0.12.0)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from tensorboard~=2.4->tensorflow) (1.30.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from tensorboard~=2.4->tensorflow) (2.24.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from tensorboard~=2.4->tensorflow) (49.2.0.post20200714)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from tensorboard~=2.4->tensorflow) (3.3.4)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from tensorboard~=2.4->tensorflow) (0.4.4)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from tensorboard~=2.4->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from tensorboard~=2.4->tensorflow) (1.8.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from tensorboard~=2.4->tensorflow) (1.0.1)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (4.2.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in c:\\users\\admin\\anaconda3\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (4.7.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (2020.6.20)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (1.25.9)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (2.10)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow) (1.3.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow) (3.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook uses keras and the tensorflow backend to do character recognition on the MNIST digits.  You need to have the `keras` and `tensorflow` packages installed.  Also for visualization of the network, you need to have `pydot` installed.\n",
    "\n",
    "We folow the example for setting up the network:\n",
    "https://github.com/Vict0rSch/deep_learning/tree/master/keras/feedforward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The MNIST data\n",
    "\n",
    "The keras library can download the MNIST data directly and provides a function to give us both the training and test images and the corresponding digits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the training set consists of 60000 digits represented as a 28x28 array (there are no color channels, so this is grayscale data).  They are also integer data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape\n",
    "#y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,\n",
       "         18,  18,  18, 126, 136, 175,  26, 166, 255, 247, 127,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  30,  36,  94, 154, 170,\n",
       "        253, 253, 253, 253, 253, 225, 172, 253, 242, 195,  64,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  49, 238, 253, 253, 253, 253,\n",
       "        253, 253, 253, 253, 251,  93,  82,  82,  56,  39,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  18, 219, 253, 253, 253, 253,\n",
       "        253, 198, 182, 247, 241,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  80, 156, 107, 253, 253,\n",
       "        205,  11,   0,  43, 154,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  14,   1, 154, 253,\n",
       "         90,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 139, 253,\n",
       "        190,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  11, 190,\n",
       "        253,  70,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  35,\n",
       "        241, 225, 160, 108,   1,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         81, 240, 253, 253, 119,  25,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  45, 186, 253, 253, 150,  27,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,  16,  93, 252, 253, 187,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0, 249, 253, 249,  64,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  46, 130, 183, 253, 253, 207,   2,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  39,\n",
       "        148, 229, 253, 253, 253, 250, 182,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  24, 114, 221,\n",
       "        253, 253, 253, 253, 201,  78,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  23,  66, 213, 253, 253,\n",
       "        253, 253, 198,  81,   2,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,  18, 171, 219, 253, 253, 253, 253,\n",
       "        195,  80,   9,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,  55, 172, 226, 253, 253, 253, 253, 244, 133,\n",
       "         11,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0, 136, 253, 253, 253, 212, 135, 132,  16,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0]], dtype=uint8)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the first 10 digits and the \"y\" value (target) associated with it&mdash;that's the correct answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "0\n",
      "4\n",
      "1\n",
      "9\n",
      "2\n",
      "1\n",
      "3\n",
      "1\n",
      "4\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x216 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(1, figsize=(14,3))\n",
    "for i in range(10):\n",
    "    plt.subplot(1,10,i+1)\n",
    "    plt.imshow(X_train[i].reshape(28,28), cmap='gray', interpolation='nearest')\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "for i in range(10):\n",
    "    print(y_train[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the Data\n",
    "\n",
    "\n",
    "The neural network takes a 1-d vector of input and will return a 1-d vector of output.  We need to convert our data to this form."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll scale the image data to fall in [0, 1) and the numerical output to be categorized as an array.  Finally, we need the input data to be one-dimensional, so we fill flatten the 28x28 images into a single 784 vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.astype('float32')/255\n",
    "X_test = X_test.astype('float32')/255\n",
    "\n",
    "X_train = np.reshape(X_train, (60000, 784))\n",
    "X_test = np.reshape(X_test, (10000, 784))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.01176471, 0.07058824, 0.07058824,\n",
       "       0.07058824, 0.49411765, 0.53333336, 0.6862745 , 0.10196079,\n",
       "       0.6509804 , 1.        , 0.96862745, 0.49803922, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.11764706, 0.14117648, 0.36862746, 0.6039216 ,\n",
       "       0.6666667 , 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
       "       0.99215686, 0.88235295, 0.6745098 , 0.99215686, 0.9490196 ,\n",
       "       0.7647059 , 0.2509804 , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.19215687, 0.93333334,\n",
       "       0.99215686, 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
       "       0.99215686, 0.99215686, 0.99215686, 0.9843137 , 0.3647059 ,\n",
       "       0.32156864, 0.32156864, 0.21960784, 0.15294118, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.07058824, 0.85882354, 0.99215686, 0.99215686,\n",
       "       0.99215686, 0.99215686, 0.99215686, 0.7764706 , 0.7137255 ,\n",
       "       0.96862745, 0.94509804, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.3137255 , 0.6117647 , 0.41960785, 0.99215686, 0.99215686,\n",
       "       0.8039216 , 0.04313726, 0.        , 0.16862746, 0.6039216 ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.05490196,\n",
       "       0.00392157, 0.6039216 , 0.99215686, 0.3529412 , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.54509807,\n",
       "       0.99215686, 0.74509805, 0.00784314, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.04313726, 0.74509805, 0.99215686,\n",
       "       0.27450982, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.13725491, 0.94509804, 0.88235295, 0.627451  ,\n",
       "       0.42352942, 0.00392157, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.31764707, 0.9411765 , 0.99215686, 0.99215686, 0.46666667,\n",
       "       0.09803922, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.1764706 ,\n",
       "       0.7294118 , 0.99215686, 0.99215686, 0.5882353 , 0.10588235,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.0627451 , 0.3647059 ,\n",
       "       0.9882353 , 0.99215686, 0.73333335, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.9764706 , 0.99215686,\n",
       "       0.9764706 , 0.2509804 , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.18039216, 0.50980395,\n",
       "       0.7176471 , 0.99215686, 0.99215686, 0.8117647 , 0.00784314,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.15294118,\n",
       "       0.5803922 , 0.8980392 , 0.99215686, 0.99215686, 0.99215686,\n",
       "       0.98039216, 0.7137255 , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.09411765, 0.44705883, 0.8666667 , 0.99215686, 0.99215686,\n",
       "       0.99215686, 0.99215686, 0.7882353 , 0.30588236, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.09019608, 0.25882354, 0.8352941 , 0.99215686,\n",
       "       0.99215686, 0.99215686, 0.99215686, 0.7764706 , 0.31764707,\n",
       "       0.00784314, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.07058824, 0.67058825, 0.85882354,\n",
       "       0.99215686, 0.99215686, 0.99215686, 0.99215686, 0.7647059 ,\n",
       "       0.3137255 , 0.03529412, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.21568628, 0.6745098 ,\n",
       "       0.8862745 , 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
       "       0.95686275, 0.52156866, 0.04313726, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.53333336, 0.99215686, 0.99215686, 0.99215686,\n",
       "       0.83137256, 0.5294118 , 0.5176471 , 0.0627451 , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        ], dtype=float32)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "For the targets (y), we need to convert the output to an array that matches what we expect the output of the neural network to be.  keras includes routines to categorize data.  In our case, since there are 10 possible digits, we want to put the output into 10 categories (represented by 10 neurons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import np_utils\n",
    "\n",
    "y_train = np_utils.to_categorical(y_train, 10)\n",
    "y_test = np_utils.to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's look at the target for the first training digit.  We know from above that it was '5'.  Here we see that there is a `1` in the index corresponding to `5` (remember we start counting at `0` in python)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build the Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll build the neural network.  We will have 2 hidden layers, and the number of neurons will look like:\n",
    "\n",
    "784 &rarr; 500 &rarr; 300 &rarr; 10\n",
    "\n",
    "We will use a **dense** network.  This means that all neurons in one layer are connected to all neurons in the next layer (sometimes the term \"fully-connected\" is used here).\n",
    "\n",
    "For each layer, we tell keras the number of output neurons.  It infers the number of inputs from the previous layer (with the exception of the input layer, where we need to tell it what to expect as input).\n",
    "\n",
    "Also, for each layer, we specify the **activation** function.  We can use \"sigmoid\" or some other choices.  We'll use\n",
    "the the _rectified linear unit_ activation function (see http://ml-cheatsheet.readthedocs.io/en/latest/activation_functions.html#relu) for all but the last layer.  See https://keras.io/activations/ for a list of activation functions supported.\n",
    "\n",
    "Finally, for some of the layers, we will specify a **dropout**.  This means that we will ignore some of the neurons in a layer during training (randomly selected at the specified probability).  This can help present overfitting of the network.  Here's a nice discussion: https://medium.com/@amarbudhiraja/https-medium-com-amarbudhiraja-learning-less-to-learn-better-dropout-in-deep-machine-learning-74334da4bfc5\n",
    "\n",
    "For the very last layer (the output layer), we use a `softmax` activation.  This is commonly used with categorical data (like we have) and has the nice property that all of entries add to 1 (so we can interpret them as probabilities)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.optimizers import RMSprop\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(500, input_dim=784))\n",
    "model.add(Activation('sigmoid'))\n",
    "#model.add(Dropout(0.4))\n",
    "#model.add(Dense(300))\n",
    "model.add(Activation('sigmoid'))\n",
    "#model.add(Dropout(0.4))\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pydot in c:\\users\\admin\\anaconda3\\lib\\site-packages (1.4.2)\n",
      "Requirement already satisfied: pyparsing>=2.1.4 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from pydot) (2.4.7)\n",
      "Requirement already satisfied: graphviz in c:\\users\\admin\\anaconda3\\lib\\site-packages (0.16)\n"
     ]
    }
   ],
   "source": [
    "!pip install pydot\n",
    "!pip install graphviz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Failed to import pydot. You must `pip install pydot` and install graphviz (https://graphviz.gitlab.io/download/), ', 'for `pydotprint` to work.')\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'create'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-58-68bb3c6a5dd6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;31m#create your model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;31m#then call the function on your model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m \u001b[0mvisualize_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-58-68bb3c6a5dd6>\u001b[0m in \u001b[0;36mvisualize_model\u001b[1;34m(model)\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mvisualize_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mSVG\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_to_dot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mshow_shapes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshow_layer_names\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdpi\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m65\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprog\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'dot'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'svg'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;31m#create your model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'create'"
     ]
    }
   ],
   "source": [
    "#from IPython.display import SVG\n",
    "#from keras.utils.vis_utils import model_to_dot\n",
    "\n",
    "#SVG(model_to_dot(model, show_shapes=True).create(prog='dot', format='svg'))\n",
    "import pydot as pyd\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "\n",
    "keras.utils.vis_utils.pydot = pyd\n",
    "\n",
    "def visualize_model(model):\n",
    "  return SVG(model_to_dot(model,show_shapes=True, show_layer_names=True, dpi=65).create(prog='dot', format='svg'))\n",
    "\n",
    "#create your model\n",
    "#then call the function on your model\n",
    "visualize_model(model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to specify what we want to optimize and how we are going to do it.  \n",
    "\n",
    "The loss (or objective) function measures how well our predictions match the expected target (an example can be the root-mean-square of the error).  For category data, like we have, the \"cross-entropy\" metric is often used.  See here for an explanation: https://jamesmccaffrey.wordpress.com/2013/11/05/why-you-should-use-cross-entropy-error-instead-of-classification-error-or-mean-squared-error-for-neural-network-classifier-training/\n",
    "\n",
    "We also need to specify an optimizer.  This could be like gradient descent.  Here's a list of the optimizers supoprted by keras: https://keras.io/optimizers/  We'll use `RMPprop`.\n",
    "\n",
    "Finally, we need to specify a metric that is evaluated during training and testing.  We'll use `\"accuracy\"` here.  This means that we'll see the accuracy of our model reported as we are training and testing.\n",
    "\n",
    "More details on these options is here: https://keras.io/models/model/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "class TrainingPlot(keras.callbacks.Callback):\n",
    "    \n",
    "    # This function is called when the training begins\n",
    "    def on_train_begin(self, logs={}):\n",
    "        # Initialize the lists for holding the logs, losses and accuracies\n",
    "        self.losses = []\n",
    "        self.acc = []\n",
    "        self.val_losses = []\n",
    "        self.val_acc = []\n",
    "        self.logs = []\n",
    "    \n",
    "    # This function is called at the end of each epoch\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        \n",
    "        # Append the logs, losses and accuracies to the lists\n",
    "        self.logs.append(logs)\n",
    "        self.losses.append(logs.get('loss'))\n",
    "        self.acc.append(logs.get('acc'))\n",
    "        self.val_losses.append(logs.get('val_loss'))\n",
    "        self.val_acc.append(logs.get('val_acc'))\n",
    "        \n",
    "        # Before plotting ensure at least 2 epochs have passed\n",
    "        if len(self.losses) > 1:\n",
    "            \n",
    "            # Clear the previous plot\n",
    "            clear_output(wait=True)\n",
    "            N = np.arange(0, len(self.losses))\n",
    "            \n",
    "            # You can chose the style of your preference\n",
    "            # print(plt.style.available) to see the available options\n",
    "            plt.style.use(\"seaborn\")\n",
    "             # Plot train loss, train acc, val loss and val acc against epochs passed\n",
    "            plt.figure()\n",
    "            plt.plot(N, self.losses, label = \"train_loss\")\n",
    "            plt.plot(N, self.acc, label = \"train_acc\")\n",
    "            plt.plot(N, self.val_losses, label = \"val_loss\")\n",
    "            plt.plot(N, self.val_acc, label = \"val_acc\")\n",
    "            plt.title(\"Training Loss and Accuracy [Epoch {}]\".format(epoch))\n",
    "            plt.xlabel(\"Epoch #\")\n",
    "            plt.ylabel(\"Loss/Accuracy\")\n",
    "            plt.legend()\n",
    "            plt.show()\n",
    "\n",
    "plot_losses = TrainingPlot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "rms = RMSprop()\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=rms, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train\n",
    "\n",
    "For training, we pass in the inputs and target and the number of epochs to run and it will optimize the network by adjusting the weights between the nodes in the layers.\n",
    "\n",
    "The number of epochs is the number of times the entire data set is passed forward and backward through the network.  The batch size is the number of training pairs you pass through the network at a given time.  You update the parameter in your model (the weights) once for each batch.  This makes things more efficient and less noisy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x396 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/20\n"
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "batch_size = 32\n",
    "model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size,\n",
    "          validation_data=(X_test, y_test), verbose=2, callbacks=[plot_losses])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test\n",
    "\n",
    "keras has a routine, `evaluate()` that can take the inputs and targets of a test data set and return the loss value and accuracy (or other defined metrics) on this data.\n",
    "\n",
    "Here we see we are > 98% accurate on the test data&mdash;this is the data that the model has never seen before (and was not trained with)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_value, accuracy = model.evaluate(X_test, y_test, batch_size=16)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting\n",
    "\n",
    "Suppose we simply want to ask our neural network to predict the target for an input.  We can use the `predict()` method to return the category array with the predictions.  We can then use `np.argmax()` to select the most probable.  Alternately, we can use `predict_classes()` to return the class (index) with the highest probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict_classes(np.array([X_test[0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's loop over the test set and print out what we predict vs. the true answer for those we get wrong.  We can also plot the image of the digit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n, (x, y) in enumerate(zip(X_test, y_test)):\n",
    "    try:\n",
    "        res = model.predict(np.array([x]), verbose=0)\n",
    "        if np.argmax(res) != np.argmax(y):\n",
    "            print(\"test {}: prediction = {}, truth is {}\".format(n, np.argmax(res), np.argmax(y)))\n",
    "            plt.imshow(x.reshape(28, 28), cmap=\"gray_r\")\n",
    "            plt.show()\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"stopping\")\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1: Batch size\n",
    "\n",
    "Adjust the batch size&mdash;how does this affect the time it takes to train for an epoch?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2: Hidden layers\n",
    "\n",
    "Remove one of the hidden layers&mdash;how does the accuracy change?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q3: Dropout\n",
    "\n",
    "What happens to the accuracy if you don't include any dropouts?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q4: Activation\n",
    "\n",
    "How does the network perform using a `\"sigmoid\"` activation function?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q5: Callbacks\n",
    "\n",
    "keras allows for callbacks each epoch to store some information.  Make a plot of the accuracy vs. epoch by adding a callback.  Take a look here for some inspiration:\n",
    "\n",
    "https://keras.io/callbacks/#example-recording-loss-history\n",
    "\n",
    "https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/History"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Going Further\n",
    "\n",
    "Convolutional neural networks are often used for image recognition, especially with larger images.  They use filter to try to recognize patterns in portions of images (A tile).  See this for a keras example: http://adventuresinmachinelearning.com/keras-tutorial-cnn-11-lines/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11.334"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "3.25*3+(0.44*3.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1232876712328767"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "9/73"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
